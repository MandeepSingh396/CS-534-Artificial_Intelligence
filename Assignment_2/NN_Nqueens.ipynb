{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6a53799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class CSV_:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.CSVfilePath = path\n",
    "\n",
    "    def readCSV_board(self, file_address=''):\n",
    "\n",
    "        # default file address\n",
    "        if len(file_address) == 0:\n",
    "            file_address = self.CSVfilePath\n",
    "\n",
    "        board_list = []\n",
    "        cost_list = []\n",
    "\n",
    "        with open(file_address, mode='r')as file:\n",
    "            csvFile = csv.reader(file)\n",
    "            board_size = int(next(csvFile)[0])  # first line is the length of board\n",
    "            index = 0\n",
    "            for lines in csvFile:\n",
    "\n",
    "                # only when there are blank lines\n",
    "                if index == 0:\n",
    "                    board = []  # new board will start after cost\n",
    "                    # continue\n",
    "\n",
    "                if index < board_size:\n",
    "                    board.append(list(lines))\n",
    "                    index += 1\n",
    "                    continue\n",
    "\n",
    "                if index == board_size:\n",
    "                    for i in range(0, len(board)):\n",
    "                        for j in range(0, len(board)):    \n",
    "                            board[j][i] = int(board[j][i])\n",
    "                    board_list.append(board)\n",
    "                    cost_list.append(int(lines[0]))\n",
    "                    index = 0\n",
    "                    # print(board)\n",
    "                    \n",
    "                    continue\n",
    "\n",
    "        file.close()\n",
    "        return board_list, cost_list\n",
    "\n",
    "csv_ = CSV_(\"F:\\Study\\Artificial Intelligence - CS 534\\Assignments\\Assignment_2\\\\Data\\\\N5.txt\")\n",
    "board_list, cost_list = csv_.readCSV_board(\"F:\\Study\\Artificial Intelligence - CS 534\\Assignments\\Assignment_2\\\\Data\\\\N5.txt\")\n",
    "# print(cost_list[-1])\n",
    "# print(len(cost_list))\n",
    "# for i in range(0,10000):\n",
    "# for line in board_list[0]:\n",
    "#     print ('  '.join(map(str, line)))\n",
    "# print(\"\\n\")\n",
    "# # print(board_list[])\n",
    "# print(len(board_list))\n",
    "\n",
    "n= len(board_list[0])\n",
    "\n",
    "def attacking_queens(grid):\n",
    "        totalhcost = 0\n",
    "        totaldcost = 0\n",
    "        for i in range(0,n):\n",
    "            for j in range(0,n):\n",
    "                #if this node is a queen, calculate all violations\n",
    "                if grid[i][j] !=0:\n",
    "                #subtract 2 so don't count self\n",
    "                #sideways and vertical\n",
    "                    totalhcost -= 2\n",
    "                    for k in range(0,n):\n",
    "                        if grid[i][k] !=0:\n",
    "                            totalhcost += 1\n",
    "                        if grid[k][j] !=0:\n",
    "                            totalhcost += 1\n",
    "                  #calculate diagonal violations\n",
    "                    k, l = i+1, j+1\n",
    "                    while k < n and l < n:\n",
    "                        if grid[k][l] !=0:\n",
    "                            totaldcost += 1\n",
    "                        k +=1\n",
    "                        l +=1\n",
    "                    k, l = i+1, j-1\n",
    "                    while k < n and l >= 0:\n",
    "                        if grid[k][l] !=0:\n",
    "                            totaldcost += 1\n",
    "                        k +=1\n",
    "                        l -=1\n",
    "                    k, l = i-1, j+1\n",
    "                    while k >= 0 and l < n:\n",
    "                        if grid[k][l] !=0:\n",
    "                            totaldcost += 1\n",
    "                        k -=1\n",
    "                        l +=1\n",
    "                    k, l = i-1, j-1\n",
    "                    while k >= 0 and l >= 0:\n",
    "                        if grid[k][l] !=0:\n",
    "                            totaldcost += 1\n",
    "                        k -=1\n",
    "                        l -=1\n",
    "        return ((totaldcost + totalhcost)/2)\n",
    "\n",
    "def queen_positions(grid):\n",
    "    queen_pos = []\n",
    "    for i in range(0,len(grid)):\n",
    "        for j in range(0,len(grid)):\n",
    "            if grid[j][i] !=0:\n",
    "                queen_pos.append(j)\n",
    "                continue\n",
    "    return queen_pos\n",
    "\n",
    "def queen_weights(grid):\n",
    "    queen_weight = []\n",
    "    for i in range(0,len(grid)):\n",
    "        for j in range(0,len(grid)):\n",
    "            if grid[j][i] !=0:\n",
    "                queen_weight.append(grid[j][i])\n",
    "                continue\n",
    "    return queen_weight\n",
    "\n",
    "def heaviest_Q(grid):\n",
    "    Qboard = queen_weights(grid)\n",
    "    HeavyQ = max(Qboard)\n",
    "    return HeavyQ\n",
    "\n",
    "def avg_weight(grid):\n",
    "    Qboard = queen_weights(grid)\n",
    "    avg = mean(Qboard)\n",
    "    return avg\n",
    "\n",
    "class training_sample:\n",
    "\n",
    "#define attributes of the training samples we need i.e. initial pattern, solved pattern and solved pattern cost by astar search algorithm.\n",
    "\n",
    "    def __init__(self, pattern, cost):\n",
    "        self.pattern = pattern\n",
    "        self.cost = cost\n",
    "        self.attacking_pairs = attacking_queens(self.pattern)        # feature 1\n",
    "        self.heaviest_queen = heaviest_Q(self.pattern)               # feature 2\n",
    "        self.average_weight = avg_weight(self.pattern)               # feature 3\n",
    "        self.queen_weights = queen_weights(self.pattern)\n",
    "        self.queen_positions = queen_positions(self.pattern)\n",
    "        \n",
    "        # self.individual_attacks = \n",
    "        # self.\n",
    "\n",
    "m = 13 #no. of features\n",
    "X =  np.empty(shape=(1,m))            # features matrix for ML model\n",
    "Y = np.reshape(cost_list, (len(cost_list), 1))             # target matrix for ML model\n",
    "sample_node_list = []                   # nodes of training samples\n",
    "\n",
    "for i in range(0,len(board_list)):\n",
    "    current = training_sample(board_list[i], cost_list[i])\n",
    "    sample_node_list.append(current)\n",
    "    new_row = [current.attacking_pairs, current.average_weight, current.heaviest_queen]\n",
    "    new_row.extend(current.queen_weights)\n",
    "    new_row.extend(current.queen_positions)\n",
    "    X = np.vstack([X, new_row])\n",
    "X = X[1:,:]\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X)\n",
    "# X1 = scaler.transform(X)\n",
    "# print(X1)\n",
    "Xnew = np.hstack([X,Y])\n",
    "\n",
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(np.mean(np.square(targets - predictions)))\n",
    "\n",
    "# model = LinearRegression()\n",
    "# inputs = X\n",
    "# targets = Y\n",
    "# model.fit(inputs, targets)\n",
    "# predictions = model.predict(inputs)\n",
    "# loss = rmse(targets, predictions)\n",
    "# print(loss)\n",
    "\n",
    "data = pd.DataFrame(Xnew, columns = ['attacks','col1_wt','col2_wt','col3_wt','col4_wt','col5_wt','col1_pos','col2_pos','col3_pos','col4_pos','col5_pos','avg','highest','cost'])\n",
    "X_inputs = data[['attacks','col1_wt','col2_wt','col3_wt','col4_wt','col5_wt','col1_pos','col2_pos','col3_pos','col4_pos','col5_pos','avg','highest']]\n",
    "Y_targets = data['cost']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68104a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = len(data)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38e583e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import jovian\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "abcc6503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 13)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a370605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_inputs, Y_targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "86b1faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_array = np.asarray(X_inputs)\n",
    "targets_array = np.asarray(Y_targets)\n",
    "Xtrain = np.asarray(Xtrain)\n",
    "Xtest = np.asarray(Xtest)\n",
    "Ytrain = np.asarray(Ytrain)\n",
    "Ytest = np.asarray(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da3106dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor(Xtrain)\n",
    "targets = torch.Tensor(Ytrain)\n",
    "inputs_test = torch.tensor(Xtest)\n",
    "targets_test = torch.tensor(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ea3af8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(inputs, targets)\n",
    "val_ds = TensorDataset(inputs_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7f7487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_percent = 0.1 # between 0.1 and 0.2\n",
    "# val_size = int(num_rows * val_percent)\n",
    "# train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "# train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f5527bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "920b1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xb, yb in train_loader:\n",
    "#     print(\"inputs:\", xb)\n",
    "#     print(\"targets:\", yb)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cd7b8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "output_size = 1\n",
    "hidden_size1 = 10\n",
    "hidden_size2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "65d1bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e454076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class N_Queens_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)                 # fill this (hint: use input_size & output_size defined above)\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.linear3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear1(xb)                          # fill this\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss =  loss_fn(out, targets)                         # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(out, targets)                        # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8a2b5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = N_Queens_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "21404c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0676, -0.0255, -0.2247, -0.1777, -0.0206, -0.0263,  0.2207,  0.2469,\n",
       "           0.2737,  0.0519, -0.2384,  0.2367,  0.0919],\n",
       "         [ 0.2314,  0.0683,  0.2265,  0.1973,  0.0780,  0.1724, -0.0779, -0.1067,\n",
       "          -0.2348,  0.0376, -0.2688,  0.1639,  0.0170],\n",
       "         [-0.0494,  0.0487, -0.1195,  0.0487, -0.1383,  0.2662, -0.0407,  0.1048,\n",
       "          -0.1930,  0.2321,  0.1419, -0.1313,  0.0994],\n",
       "         [-0.0289,  0.2199,  0.2709,  0.1353, -0.2350,  0.0121, -0.2763,  0.0300,\n",
       "           0.0316, -0.1902, -0.2254, -0.2505, -0.0065],\n",
       "         [-0.0108,  0.2200,  0.2135,  0.1210, -0.2033, -0.0481,  0.0427, -0.1151,\n",
       "           0.0161, -0.1466,  0.2368,  0.1889, -0.0164],\n",
       "         [ 0.0848, -0.1713,  0.2254,  0.1074,  0.1960,  0.0554, -0.1698, -0.2227,\n",
       "           0.0266, -0.0149, -0.0231, -0.0679, -0.2641],\n",
       "         [-0.0962, -0.0159,  0.0394,  0.1601,  0.1884, -0.0085,  0.0409,  0.0496,\n",
       "          -0.0746, -0.0628, -0.2011, -0.0811,  0.0955],\n",
       "         [ 0.1043, -0.0665, -0.2115,  0.1231, -0.0055,  0.2227, -0.0855,  0.2142,\n",
       "           0.1065, -0.1925,  0.1006,  0.2745, -0.2618],\n",
       "         [ 0.1593, -0.0701, -0.1072, -0.1172,  0.0041,  0.2507,  0.2230,  0.1475,\n",
       "           0.2608, -0.2662, -0.2438, -0.0121, -0.0677],\n",
       "         [-0.1534,  0.0207,  0.1183, -0.1488,  0.1209, -0.2164,  0.0736,  0.2348,\n",
       "           0.2088, -0.2431,  0.1213,  0.0492,  0.1640]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1622,  0.1400, -0.2642,  0.0043,  0.0092,  0.1602, -0.2615, -0.2320,\n",
       "         -0.0391, -0.1668], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.7837e-01, -2.0860e-01, -1.3217e-01,  1.5944e-01, -1.6450e-01,\n",
       "           1.4988e-01,  5.7113e-02,  1.0181e-01,  2.9712e-01,  1.5319e-01],\n",
       "         [ 1.1060e-01, -1.9679e-01, -2.9752e-01, -1.5573e-01, -1.5972e-01,\n",
       "           1.6369e-01,  1.5216e-01,  1.4418e-01, -6.7947e-02, -3.7093e-02],\n",
       "         [-3.1021e-01, -6.5832e-02,  1.2803e-01,  9.6836e-02,  1.0273e-03,\n",
       "           1.6796e-02, -2.1167e-01,  1.4956e-01, -1.5997e-01,  7.0721e-03],\n",
       "         [ 8.5908e-04,  3.3909e-02, -4.0751e-02,  7.2592e-02,  1.6530e-01,\n",
       "          -4.0299e-02,  4.5290e-02, -1.4864e-01, -5.1886e-05,  1.3796e-01],\n",
       "         [-1.5246e-03, -8.4067e-02,  8.8427e-02,  3.0107e-01, -2.2037e-01,\n",
       "          -2.2167e-01,  1.3311e-01,  3.6156e-02,  2.9886e-01,  1.8315e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0626,  0.0390,  0.0351,  0.3124,  0.0011], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3267,  0.4299,  0.3354, -0.1083,  0.1663]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2405], requires_grad=True)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b5db91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dbe9142a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3723841704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use the the evaluate function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3044334831.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3044334831.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3426477581.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Generate predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# fill this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3426477581.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m# fill this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83b46856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3426477581.py:21: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss =  loss_fn(out, targets)                         # fill this\n",
      "C:\\Users\\MANDEE~1\\AppData\\Local\\Temp/ipykernel_43580/3426477581.py:29: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = loss_fn(out, targets)                        # fill this\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 72.5937\n",
      "Epoch [40], val_loss: 73.6936\n",
      "Epoch [60], val_loss: 71.9944\n",
      "Epoch [80], val_loss: 72.3536\n",
      "Epoch [100], val_loss: 72.3076\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "history1 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7372ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)                # fill this\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f03ae77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([3.0000, 4.2000, 7.0000, 7.0000, 1.0000, 3.0000, 6.0000, 4.0000, 2.0000,\n",
      "        4.0000, 2.0000, 4.0000, 3.0000])\n",
      "Target: tensor(77.)\n",
      "Prediction: tensor([130.4066])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "14182556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([5.0000, 3.6000, 9.0000, 1.0000, 3.0000, 2.0000, 3.0000, 9.0000, 0.0000,\n",
      "        3.0000, 0.0000, 3.0000, 3.0000])\n",
      "Target: tensor(36.)\n",
      "Prediction: tensor([129.5754])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[500]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e769e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([4.0000, 6.4000, 9.0000, 9.0000, 5.0000, 7.0000, 9.0000, 2.0000, 4.0000,\n",
      "        0.0000, 1.0000, 4.0000, 4.0000])\n",
      "Target: tensor(164.)\n",
      "Prediction: tensor([135.7244])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[50]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cc4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
